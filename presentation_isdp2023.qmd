---
title: "Machine Learning can Advance Theory Formation in the Social Sciences"
subtitle: "Funded by NWO Veni grant VI.Veni.191G.090<br>Paper: [doi:10.1002/icd.2370](https://doi.org/10.1002/icd.2370)"
author: "Caspar J. Van Lissa"
institute: "Tilburg University, dept. Methodology & Statistics"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs") })
format: revealjs
bibliography      : ["manuscript/references.bib", "presentation/all_refs.bib"]
---

```{r}
#| label = "setup",
#| include = FALSE
#css: https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

## Central thesis {.smaller}

_Machine learning_ can help advance _theory formation_ in the social sciences

* Replication crisis [@scheelWhyMostPsychological2022; @lavelleWhenCrisisBecomes2021]
* Current solutions improve deductive research (theory-testing)
    + preregistration [@peikertReproducibleResearchTutorial2021]
    + replication
    + questionable research practices [@wichertsDegreesFreedomPlanning2016]

Many preregistered hypotheses are not supported (56%) [@scheelExcessPositiveResults2021]

* Lack of "good theories" another explanation for replication crisis

## Defining theory {.smaller}

Why do we need theory?

* Useful as an instrument of cumulative knowledge acquisition
* Communicating social scientific research to its consumers (parents, practitioners, policy makers)

## Deduction vs induction

```{r}
#| out.width = "40%"
knitr::include_graphics("presentation/empiricalcycle.png")
```

* Empirical cycle [@degrootMethodologieGrondslagenVan1961]
* Lack of theory cannot be overcome by improving deductive practices
* Theory formation requires inductive (exploratory) research [@creswellDesigningConductingMixed2017]

## Rigorous exploration

How can we improve exploratory research?

* Confirmatory methods poorly suited to exploratory research
    + p-values: 5% Type I error prob is consistent with 14-50% false discovery rate [@vidgenPValuesMisunderstoodMisused2016]
    + Depending on prior probability of hypotheses being true
    + Model fit indices: manually specify models, no guarantee that best model is in set
* Role of flexibility: there are infinite ways to explore
* "unguided exploration" is effortful and inflates the risk of spurious results

## Machine learning

**Machine learning**:

* automated model building

Psychology can benefit from its superior predictive performance [@yarkoniChoosingPredictionExplanation2017]

**NEW**: Epistemological implications of ML for theory formation [@vanlissaDevelopmentalDataScience2022]


## Phenomena detection  

First step in *Theory Construction Methods* is identifying relevant phenomena [@borsboomTheoryConstructionMethodology2020]

* Phenomena: stable features of the world reliably evidenced by patterns in data (Woodward, 1989)

Machine learning  [@vanlissaMappingPhenomenaRelevant2021]

* Unsupervised learning methods find patterns in data
* Text mining finds patterns in published literature

## Holistic approach {.smaller}

Every study examines only a piece of the puzzle; we never see the complete picture

Machine learning accommodates more predictors than classical methods

* Regularization 
* Variable selection

Including all relevant predictors is important:

* Good theory incorporates most important causes
* Cannot assess the relative utility of predictors across studies
* Include potential predictors from various theories, and undertheorized factors


## Complex effects

Social scientific theories rarely account for complex effects

Many machine learning methods accommodate:

* non-linear effects 
* higher-order interactions, without having to specify the nature of these effects a-priori.
* Automatic: tree-based methods
* Manual: penalized methods

## Theoretical elements

Some machine learning methods incorporate theoretical elements

* E.g.: assumption that development follows a latent growth curve (LGC).
* SEM forests [@brandmaierTheoryguidedExplorationStructural2016]
* Regularized SEM [@jacobucciRegularizedStructuralEquation2016], (Ernst & Peikert 2022)

When the theory is a (nomological) network:

* LASSO-penalized Gaussian graphical model (GGM) [@epskampGeneralizedNetworkPsychometrics2017]
* E.g.: network theory of major depression [@cramerMajorDepressionComplex2016]

All of these methods allow for theory guided exploration using machine learning

## Person-centered approaches {.smaller}

Explain heterogeneity at a more fine-grained level than the whole sample

* Unsupervised learning methods
    + Group individuals to maximize homogeneity of some outcomes
    + "Which individuals are similar?"
* Tree-based models
    + Group individuals by predictors to maximize homogeneity of outcomes
    + "Why are these individuals similar?"
* Mixed-effects / multilevel models (DSEM, RI-CLPM)
    + Often model but rarely explain heterogeneity in within-person effects
    + Regularization (e.g., regularized SEM)

## Generalizability

When using data models to guide theory formation, generalizability is essential [@haslbeckModelingPsychopathologyData2021]

Machine learning

* Incorporates checks and balances to curtail *overfitting*
* Maximizes predictive performance and generalizability of results
* Cross-validation to estimate predictive accuracy [@hastieElementsStatisticalLearning2009]
* Possible to estimate generalizability to representative subsample (e.g., Douglas, Sutton, Van Lissa et al., 2023)

<!-- Any model captures both *signal* and *noise* -->

<!-- **Overfitting**: model captures so much noise that it generalizes poorly to new samples -->

```{r}
#| out.width = "40%"
library(ggplot2)
colors <- c("Variance" = "red", "Bias" = "green", "Total error" = "black")

ggplot() +
  xlim(-3, 3) +
geom_function(
  data = NULL,
  stat = "function",
  position = "identity",
  fun = ~.x^2,
  na.rm = FALSE,
  inherit.aes = TRUE,
  linewidth = 1,
  aes(colour = "Total error")
) +
  geom_function(
    data = NULL,
    stat = "function",
    position = "identity",
    fun = ~2^.x -2,
    na.rm = FALSE,
    inherit.aes = TRUE,
    aes(colour = "Bias"),
    linewidth = 1
  )+
  geom_function(
    data = NULL,
    stat = "function",
    position = "identity",
    fun = ~2^-.x -2,
    na.rm = FALSE,
    inherit.aes = TRUE,
    aes(colour = "Variance"),
    linewidth = 1
  ) +
  labs(x = "Model complexity",
       y = "Optimal model complexity",
       color = "Legend") +
  scale_color_manual(values = colors) +
  geom_vline(xintercept = 0, linetype = 2) +
  theme_bw() +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```


## From models to theory {.smaller}

Naive interpretative approach

* Variable importance metrics
    + congruent with theoretical assumptions about important predictors?
    + any theoretically important predictors rank low?
    + any undertheorized factors rank high?
* Marginal associations
    + non-linear effects?
    + high importance but flat marginal association?
* Abductive formal theory construction (AFTC) framework [@haslbeckModelingPsychopathologyData2021]
    + Translate insights into formal theory
    + Conduct "posterior predictive check" to check fit with data
    + Discrepancies: amend formal theory

<!-- ## Summary -->

<!-- * There is a paucity of good theory -->
<!-- * Need for exploratory research for theory formation -->
<!-- * Machine learning for rigorous exploration -->
<!--     + automates model building -->
<!--     + incorporates checks and balances for generalizable results -->
<!-- * Unsupervised learning can assist in phenomenon detection -->
<!-- * Supervised learning to identify important predictors -->
<!-- * Some algorithms incorporate basic theoretical elements -->

## Example: TMSR {.smaller}

* Identifying relevant phenomena
* Narrative reviews: small samples, confirmation bias, emphasize positive results [@littellEvidencebasedBiasedQuality2008]
* Text Mining Systematic Review [@vanlissaMappingPhenomenaRelevant2021]
    + Unlimited sample size, transparent, objective, reproducible
* 6653 papers on **emotion regulation** in **adolescence** [age 10-24]

Paper: <https://doi.org/10.1007/s40894-021-00160-7>
Reproducible code and data: <https://github.com/cjvanlissa/veni_sysrev>

Workflow for Open Reproducible Code in Science (WORCS)  [@vanlissaWORCSWorkflowOpen2020]



## Co-occurrence graph {.smaller}

```{r}
#| label = "networks1",
#| eval = TRUE,
#| results = "asis",
#| out.width = "100%"
knitr::include_graphics("presentation/tmnetworks_small.png")
```

Author keywords (a) and abstracts (b)

## Results {.smaller}

* TM analyses retrieve constructs from theoretical literature
    + Especially pertaining to neurodevelopment and socialization
    + This suggests validity
* Substantial correspondence between keyword and abstract network
    + This suggests reliability
* Networks are sparse; few connections among constructs:
    + Fragmented literature, as noted by prior reviews

## Undertheorized themes

* Developmental disorders
* Physical health (sic)
* External stressors
* Structural disadvantage
* Addictive behavior
* Identity and moral development
* Sexual development

## Implications

* Empirical research relies on theory; under-theorized phenomena may be overlooked
    + TMSR offers guidance for phenomena to consider as confounders/causes
* Unembedded terms indicate promising areas of future research
* TMSR network can serve as proto-theoretical nomological network

## Example: Predictors of Development {.smaller}

* What are important predictors of ER development trajectories?
* What is the nature of association of predictors with trajectories?
* 497 Dutch adolescents (283 boys; age at T1: M =13.03, SD = 0.46) 
* Predictors: 87 (Demographics, Biological, Individual differences, Risk behavior, Relationship quality, Parenting, Conflict resolution styles)
* Outcome: Difficulties in emotion regulation [@gratzMultidimensionalAssessmentEmotion2004]
* Code and synthetic data: <https://github.com/cjvanlissa/veni_forest>

## SEM Forests

```{r}
#| out.width = "70%"
knitr::include_graphics("tree.png")
```


## Variable importance

```{r, out.width="90%"}
knitr::include_graphics("pcomb2.png")
```

## Variable importance 2

```{r, out.width="100%"}
knitr::include_graphics("violin.png")
```

## Marginal association

```{r, out.width="40%"}
knitr::include_graphics("plots/pdp1-12.png")
```


## Results {.smaller}

* Best predictors: Personality and conflict behaviors
* Negative parenting more predictive than positive parenting

Less important than expected:

* SES
* Bullying/victimization
* Delinquency
* Substance use
* Monitoring

* Most predictors show non-linear effects

## Reflection content

* Proximal factors more predictive of ER development than distal predictors
    + Order mirrors bioecological model
* Most important predictors are routinely assessed (big 5) or overt (conflict)
  + Prime candidates for early risk assessment
  + Conflict resolution behavior can be taught
    - Target for intervention if association is causal
* Emphasis on parenting (in literature and theory) might not be justified
  + Congruent with RI-CLPM showing few parenting effects in adolescence [@vanlissaRoleFathersMothers2019]


## Reflections form

* Many predictors show non-linear effects: Emotion dysregulation only for +/-1SD
* Some predictors show almost no marginal effect (e.g., father's age, drug use)
  + This suggests they might be important in **interactions**

## Conclusions

* Machine learning reveals blind spots in existing theory
    + Missing constructs, relative importance, functional form
* ML can detect patterns in published research and primary data
* Does not solve the "inductive problem"
    + Still your responsibility to consolidate insights into theory
* Ignoring causality limits interpretability of machine learning
    + Incorrect direction of causality: meaningless results
    + Conditioning on a collider: biased results
    


<!-- ## Future direction 1: Formal theoretical object -->

<!-- Formal theories are expressed in mathematical terms -->

<!-- * unambiguous -->
<!-- * logically sound -->
<!-- * explicates assumptions -->
<!-- * reveals ambiguities and gaps in knowledge -->
<!-- * facilitates conveying ideas to others -->
<!-- * applying rules of formal logic implies testable hypotheses -->
<!-- * refutation of hypotheses dictates specific modifications -->

<!-- ## Characteristics of formal theory -->

<!-- According to Meehl: -->

<!-- 1. phenomena to be explained -->
<!-- 2. putative causal connections between them -->
<!-- 3. direction of the effect -->
<!-- 4. relative importance of predictors -->
<!-- 5. interaction effects -->
<!-- 6. functional form of associations -->

<!-- ## Formal theory -->

<!-- * Characteristics 1-2 can be described by a causal network (DAG) -->
<!-- * Characteristics 3-6 refer to the nature of associations within that network -->

<!-- Augmented causal networks (ACN, see also Crielaard et al., 2022) -->

<!-- * encode both causal relationships and the nature of those relationships -->
<!-- * imply testable hypotheses -->
<!-- * shared in plain text, e.g., YAML or RDF -->
<!-- * version controlled -->
<!-- * shared conform FAIR software principles, -->
<!-- to be used and updated through distributed collaboration -->

<!-- ## Learning a causal network -->

<!-- * Using TMSR, based on what previous authors have written -->
<!-- * Using causal discovery, based on large panel studies -->
<!-- * Using ESM data to leverage precedence in time -->
<!--     + Causality requires association, precedence in time, and nonspuriousness -->

<!-- ## Future direction 2: Functional form -->

<!-- Previous work: Post-hoc interpretation of marginal associations -->

<!-- Future direction: Use a-priori interpretable machine learning -->

<!-- * Symbolic regression applies deep learning or genetic algorithms to learn a mathematical formula that describes the relationship between an outcome and its predictors -->

## References {.smaller}

Van Lissa, C. J. (2022). Developmental data science: How machine learning can advance theory formation in Developmental Psychology. ICD. DOI:10.1002/icd.2370

Van Lissa, C. J. (2022). Complementing preregistered confirmatory analyses with rigorous, reproducible exploration using machine learning. Religion, Brain & Behavior. DOI:10.1080/2153599X.2022.2070254

Van Lissa, C. J., Beinhauer, L., Branje, S., & Meeus, W. (2022). Using machine learning to identify early predictors of adolescent emotion regulation development. Journal of Research on Adolescence. DOI:10.31234/osf.io/rbqf9

Van Lissa, C. J. (2021). Mapping Phenomena Relevant to Adolescent Emotion Regulation: A Text-Mining Systematic Review. ARR. DOI:10.1007/s40894-021-00160-7

Van Lissa, C. J., et al., (2022). Using machine learning to identify important predictors of COVID-19 infection prevention behaviors during the early phase of the pandemic. Patterns, 3(4), 100482. DOI:10.1016/j.patter.2022.100482

Douglas, K., Sutton, R. M., Van Lissa, C. J., Wolfgang, S., Jannis, K., Maximilian, A., ... & N Pontus, L. (2023). Identifying Important Individual-and Country-Level Predictors of Conspiracy Theorizing. EJSP. DOI: 10.1002/ejsp.2968

## 
